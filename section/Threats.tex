\label{sec:threats}
Our study is subject to several threats to validity. In this section we present these threats and the strategies we have used to mitigate them.\\

Firstly, our study is subject to the threat of construct validity. Indeed, the \emph{FAST} model generated by our approach might not be correct and consistent with the defined metamodel, or it might misrepresent the input deep learning program. To mitigate this threat, we have set up unit tests for each visiting method. These unit tests enable us to check that the methods implemented in the importer are correctly implemented and that the \emph{FAST} model generated conforms to the defined metamodel. In addition, for a set of test data (fictive samples), we have implemented functional tests (Smock Testing) to check that the \emph{FAST} model generated does indeed represent the input deep learning program.\\

Secondly, our study is subject to the threat of internal validity. There remains a risk that the conclusions obtained are not caused by the input source code. To mitigate this threat, in addition to testing our system on synthetic examples, we used real projects collected from Github to validate our system's operation.\\

Thirdly, our study is subject to the threat of external validity. There is a risk that the results obtained may not be generalizable. To mitigate this threat, we randomly collected projects from Github to represent different applications of the CNN architecture.\\

Fourthly, our study is subject to the threat of reliability validity. Finally, there is a risk that the results obtained may not be reproducible. To mitigate this threat, in addition to using projects from different applications of the CNN architecture, we used projects implemented in the three most widely used open-source libraries in the industry (Tensorflow, PyTorch, and Keras).