\label{sec:introduction}

L'apprentissage profond est un sous ensemble du machine learning qui utilise des
réseaux de neurones artificiels pour apprendre des données non structurées.
L'apprentissage profond est devenu très populaire ces dernières années grâce à
ses performances dans plusieurs domaines comme la reconnaissance d'image, la
reconnaissance vocale, la traduction automatique, etc. Les réseaux de neurones
artificiels sont des modèles mathématiques qui sont inspirés du fonctionnement
du cerveau humain. Ils sont composés de plusieurs couches de neurones qui sont
connectés entre eux. Chaque neurone est composé d'une fonction d'activation qui
permet de calculer la sortie du neurone en fonction de ses entrées. Il existe
plusieurs types d'architecture de réseaux de neurones artificiels. Ses
architecture ont été développées pour répondre à des problèmes spécifiques tels
que l'architecture de convolution pour la reconnaissance d'image, les réseaux de
neurones récurrents pour la reconnaissance vocale, etc. Dans ce papier, nous
nous intéressons à l'architecture de convolution car elle permet de traiter un
large ensemble de problèmes comme la reconnaissance d'image, la reconnaissance
de texte, la reconnaissance de séquence, etc. Par ailleurs l'architecture de
convolution fait partie des architectures feed-forward qui sont une classe de
réseaux de neurones artificiels qui sont composés de plusieurs couches de
neurones  et qui ne contiennent pas de cycles. Les réseaux de neurones
feed-forward sont les plus utilisés dans l'apprentissage profond.\\


\subsection{Convolutional Neural Network}
Nous parlerons dans ce papier de programmes d'apprentissage profond pour
désigner les programmes contenant les réseaux de neurones convolutifs. Une
architecture de réseaux de neurones est de type feed-forward car elle ne
contient pas de cycles. elle est composée de trois principales étapes suivantes:\\

\subsubsection*{Convolution}
La convolution est l'action de faire passer les filtres sur une image pour
extraire des patterns. Un filtre est un réseau de neurone classique qui scanne
une image sous partie par sous partie afin de détecter un pattern. Le filtre
scanne une fenetre (partie) de l'image puis calcule la sortie en un pixel. Ainsi
le filtre navige sur toute l'image pour calculer la sortie de chaque pixel d'une nouvelle image.
La nouvelle image est appelée feature map. La convolution augmente la profondeur de
l'image en entrée car elle génère plusieurs feature maps tout en réduisant sa taille.
On rappelle que chaque layer de la profondeur est une image (taille réduite)
générée par un filtre.\\

\subsubsection*{Pooling}
Le pooling est une opération qui permet de réduire la taille de l'image en
selectionant le pixel le plus grand dans une fenetre. Il permet de réduire la
consommation en calculs et en mémoire. Il permet aussi de réduire le sur
l'overtfitting sur les données d'entrainement car on pert l'information sur la
position des patterns détectés. On va donc utiliser le pooling sur les feature
maps générées par la convolution. Chaque convolution est suivie d'un pooling
et on répète cette opération plusieurs fois. Plus on va en profondeur de la
convolution, plus on détecte des patterns précis susceptible de faciliter la classification.\\

\subsubsection*{Flatten}
Le flatten est l'opération qui permet de transformer les feature maps générées à
la suite des convolution et pooling en un seul vecteur. Ce vecteur est ensuite
utilisé comme entrée d'un réseau de neurones classique (\emph{dense layer}). De ce
neurone sortira l'output du réseau de neurones convolutifs.

\subsection{Odeur de conception}
Le code smell est un mauvais choix de conception et d'implementation qui peut
avoir un impact négatif sur la qualité du logiciel \cite{fowler1997refactoring}.
Tout comme n'importe quel programme, les programmes d'apprentissage profond
peuvent contenir des odeurs de code. Nous nous intéressons dans ce papier aux
odeurs de conception car ce sont des odeurs introduits tôt dans le cycle de
développement du logiciel et elles peuvent avoir un impact négatif conséquent
sur la performance et la qualité du logiciel. Ses odeurs sont introduites par le
développeur lors de la phase de  conception du logiciel.\\ Nikanjam et al. ont
proposé une liste de 8 odeurs de conception pour les programmes d'apprentissage
feed-forward \cite{nikanjam2019deep}. Ils ont trouvé ses odeurs dans des revue
de litterature et les plateformes open source Github et StackOverflow. Leur étude empirique a montré que les
odeurs proposées sont perçu comme pertinent par les développeurs. Nous nous
sommes de se fait basé sur cette liste d'odeurs pour proposer aux développeurs
un systeme de détection automatique de ses odeurs.\\ Les 8 odeurs proposées sont
classées en deux catégories principales comme suit:
\begin{enumerate}
    \item \textbf{Odeurs de conception lors de la convolution et le pooling} : Ces
          odeurs sont introduites lors de la formation des feature maps. Elles sont liées
          à la taille de la feature map ou du filtre et à la disposition des couhes. La liste des odeurs est présentée dans le tableau \ref{tab:convolutionalSmellsConv}.
    \item \textbf{Odeurs de conception liées à l'usage des méthodes de régulation} : Ces odeurs sont
          introduites lors de l'utilisation de la régularisation. Elles sont liées à
          l'utilisation des méthodes de régularisation comme la couche dropout et la
          disposition de ses méthodes. La liste des odeurs est présentée dans le tableau \ref{tab:convolutionalSmellsReg}.
\end{enumerate}


\begin{table*}[h]
    \centering
    \caption{Odeurs de conception dans les couches de convolution et de pooling}
    \label{tab:convolutionalSmellsConv}
    \begin{tabular}{ll}
        \toprule
        \multicolumn{1}{c}{\textbf{Design Smell}} &
        \multicolumn{1}{c}{\textbf{Description}}                                                                                                                                                       \\ \midrule
        Non-expanding feature map                 &
        \begin{tabular}[c]{@{}l@{}}Conserver le même nombre de caractéristiques ou \\ le diminuer à mesure que l'architecture devient plus profonde.\end{tabular}                                      \\
        Losing local correlation                  &
        \begin{tabular}[c]{@{}l@{}}Commencer par une taille de fenêtre relativement grande pour\\ le filtrage spatial et la conservent pour toutes les couches convolutives.\end{tabular}              \\
        Heterogeneous blocks of CNNs              &
        \begin{tabular}[c]{@{}l@{}}Construire un modèle plus profond en empilant uniquement\\ un ensemble de couches de convolution et de mise en commun\\ sans configuration appropriée.\end{tabular} \\
        Too much down-sampling                    &
        \begin{tabular}[c]{@{}l@{}}Utilisation du pooling juste après chaque couche\\ convolutive, en particulier pour les premières couches.\end{tabular}                                             \\
        Non-dominating down-sampling              &
        Utilisation de l'average-pooling.                                                                                                                                                              \\ \bottomrule
    \end{tabular}
\end{table*}


\begin{table*}[h]
    \centering
    \caption{Odeurs de conception liées à la régularisation}
    \label{tab:convolutionalSmellsReg}
    \begin{tabular}{ll}
        \toprule
        \multicolumn{1}{c}{\textbf{Design Smell}} & \multicolumn{1}{c}{\textbf{Description}}
        \\ \midrule
        Useless Dropout                           & Utilisation du Dropout avant les pooling layer.                                                                                                                                        \\
        Bias with Batchnorm                       &
        \begin{tabular}[c]{@{}l@{}}Conserver les valeurs de biais dans les couches lors \\ de l'utilisation de batchnorm. \\ Les couches d'apprentissage d'un FNN bénéficient \\ d'un biais avec différentes initialisations.\end{tabular} \\
        Non-representative Statistics Estimation  & Utilisation du batchnorm après le dropout.                                                                                                                                             \\ \bottomrule
    \end{tabular}
\end{table*}



\subsection{Meta-modeling}

Thomas Kühne définit un  modèle comme un artefact formulé dans un langage de
modélisation, tel qu'UML, décrivant un système à l'aide de différents types de
diagrammes \cite{kuhne2006matters}. Cette représentation abstraite d'un système
est définit par un autre modèle appelé méta-modèle. Un modèle permet d'analyser,
comprendre et transformer un système efficacement.
Ses opérations peuvent être automatisées \cite{gonzalez2014formal}. Il existe
plusieurs types de modèles tels que les modèles de comportement (représent le
comportement dynamique du système) ou de conception (représent la structure
statique du systeme).\\ Dans ce papier, nous nous intéressons aux modèles de
conception car
les odeurs étudiées sont représentées sous forme statique et sont introduit au
niveau de la stucture du système.\\

Nous utiliserons par ailleurs les modèles \textbf{FAST} (\emph{Famix Abstract Syntax Tree}) pour représenter les systèmes étudiés dans ce papier. Les modèles
FAST sont des arbres de syntaxe issue du langage de programmation orienté objet
Pharo \cite{black2010pharo, bergel2013deep, zaitsev2020characterizing}. Il hérite du modèle \textbf{FAMIX} qui est d'après la définition de
Tichelaar et al. une représentation indépendante du langage d'un code source
orienté objet. Il s'agit d'un modèle entité-relation qui modélise le code source
orienté objet au niveau de l'entité du programme \cite{891485} \cite{demeyer1999famix}.
Les modèles FAST sont développés dans l'envirennement de retroengineering Moose \cite{ducasse2000moose}.\\\\



\subsection{Motivation and research questions}
Les développeurs ont identifié dans l'étude de Nikanjam et al. les odeurs de
conception proposées, leur pertinence et donc l'interet de les éviter.
Cependant, il n'existe pas de système de détection automatique de ses odeurs
dans la littérature. Nous proposons dans ce papier ce système qui
permettra de détecter ses odeurs dans les programmes d'apprentissage profond
CNN. De plus notre système couvrira les Frameworks open source les plus utilisés sur le
marché. Pour ce faire, nous avons défini les questions de recherche suivantes:\\

\emph{\\RQ1:\RQOne} % La technique de détection

\emph{\\RQ2:\RQTwo} % La répartition

\emph{\\RQ3:\RQThree} % Les relations

Notre papier est organisé comme suit: la section \ref{sec:background} présente
les travaux passé lié à notre sujet. La section \ref{sec:studyDesign} décrit la
collection et le traitement des données. La section \ref{sec:results} présente
les résultats. La section \ref{sec:discussion} discute les
résultats précedement présentées. La section \ref{sec:threats} présente les menaces à la
validité et la section \ref{sec:limitationsFutureWork} présente les limites de notre étude et les travaux futurs.
